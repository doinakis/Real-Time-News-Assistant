\section{\emph{Reader}}
\label{sec:reader_exp}
Ο \emph{Reader} αποτελεί έναν από τους σημαντικότερους κόμβους του συστήματος. Τα πειράματα που πραγματοποιήθηκαν μελέτησαν την απόδοση διάφορων μοντέλων στην εύρεση απάντησης σε κείμενο το οποίο περιείχε τη σωστή απάντηση. Επίσης, μελετήθηκαν διάφορα μήκη εισόδων στα μοντέλα (\emph{max\_seq\_len}) και διαφορετικό βήμα κινούμενου παραθύρου (\emph{doc\_stride}). Από τους πίνακες \ref{tab:reader_scores1}, \ref{tab:reader_scores2} φαίνεται ότι το μοντέλο με τη μεγαλύτερη απόδοση είναι το \emph{xlm-roberta-large-squad2}\footnote{\url{https://huggingface.co/deepset/xlm-roberta-large-squad2}} από την \emph{deepset} το οποίο είναι εκπαιδευμένο στο \emph{SQuAD2}\footnote{\url{https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/}} και χρησιμοποιείται με τη μέθοδο \emph{zero-shot}, καθώς δεν είναι εκπαιδευμένο στα ελληνικά. Επιπλέον, τα δύο ελληνικά μοντέλα \emph{squad\_bert\_el}\footnote{\url{https://huggingface.co/Danastos/squad_bert_el}} και \emph{qacombination\_bert\_el}\footnote{\url{https://huggingface.co/Danastos/qacombination_bert_el}} έχουν παρόμοια απόδοση. Οι παράμετροι \emph{max\_seq\_len} και \emph{doc\_stride} επιλέχθηκαν με τις τιμές $256$ και $128$ αντίστοιχα, καθώς η απόδοση του με μεγαλύτερες τιμές παρουσίασε ελάχιστη βελτίωση. Ταυτόχρονα αξίζει να σημειωθεί ότι τα ελληνικά μοντέλα προβλέπουν σε μικρότερο χρόνο από ότι το \emph{xlm-roberta-large-squad2}, το οποίο ήταν αναμενόμενο γνωρίζοντας ότι το μέγεθος του τελευταίου. Το μοντέλο που χρησιμοποιήθηκε στη παρούσα υλοποίηση ήταν \emph{xlm-roberta-large-squad2}\footnote{Το μοντέλο \emph{xlm-roberta-large-squad2} έχει max\_seq\_len 256, επομένως στο πείραμα με τα 512 το παράθυρο δεν επικαλύπτει τη προηγούμενη με την επόμενη είσοδο}, καθώς η ακρίβεια του μοντέλου είναι κύριας σημασίας για το σύστημα.

\input{tables/readers-256-128}

\input{tables/readers-512-256}